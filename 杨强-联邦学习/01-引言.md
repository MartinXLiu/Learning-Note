# 引言
当今人工智能仍然面临两大挑战：

**在大多数工业中，数据以 “孤岛”形式存在**

**大数据的隐私和安全问题**

本章重点关注谷歌将联邦学习用于智能手机上的语言预测模型这个案例，关键技术：联邦平均(Federated Averaging) 

## 联邦学习的定义

谷歌最开始提出联邦学习时是为了解决C端用户终端设备上模型训练的问题。
 C端用户手机上的智能软件提供服务时背后都得依靠模型，而模型的训练学习全部要基于用户的数据。比如手机上的输入法，基于不同人的打字拼音习惯，输入法会不停更新会慢慢和每个人的打字习惯进行匹配，用户会觉得输入法越来越智能；

那么过去这些手机输入法是如何进行模型训练的？
过去的做法： 将用户每天产生的行为数据全部上传至云端服务器，部署在服务器上的模型基于上传的数据进行训练，然后更新模型，最终实际应用时本地需要请求云端服务。

 上述这种模型训练的方式，我们也叫做“集中式模型训练”，这种方式有两个弊端：

>1.无法保证用户的数据隐私：服务商将用户的数据全部采集到了服务器上进行统一管理。这种方式在监管对个人数据隐私管控越来越严的情况下，会越来越受限；

>2.实时性难以保证：模型在应用时需要通过网络请求云端的模型，在网络延迟或者没有网络的情况下，模型没办法发挥它的作用；

谷歌提出了一种新的解决方案，并将它命名为“Federated Learning”。总的来说就是：用户数据不出本地，所有模型的训练都是在设备本地进行。本地模型训练完毕后将得到的模型参数or下降梯度，经过加密上传至云端，云端模型接收到所有上传的加密参数or梯度后，结合所有的参数值进行统一的聚合，比如通过加权平均得到新的模型参数or下降梯度，然后将新的结果再重新下发到本地，本地更新得到一个全新的模型；
 这种方式我们又叫作“分布式模型训练“。




## 联邦学习分类

如图： 
![联邦学习分类](https://ask.qcloudimg.com/http-save/yehe-1051732/23445b4c91267fd09ed9fa041c5271c0.png)
横向联邦学习（按样本划分的联邦学习）：参与方的数据有重叠的数据特征，但样本不同

纵向联邦学习（按特征划分的联邦学习）：参与方的样本是对齐的，但特征不同

联邦迁移学习（federated transfer learning）：参与方数据样本和特征重叠都很少


### 横向联邦学习
横向联邦学习系统的训练过程通常由如下四个步骤组成:

>步骤1:各参与方在本地计算模型梯度，并使用同态加密、差分隐私等加密技术，对梯度信息进行掩饰并将掩饰后的结果(简称为加密梯度)发送给聚合服务器。
>步骤2:服务器进行安全聚合操作，如使用基于同态加密的加权平均。
>步骤3:服务器将聚合后的结果发送给各参与方。
>步骤4:各参与方对收到的梯度进行解密，并使用解密后的梯度结果更新各自的模型参数。

#### 经典算法


### 纵向联邦学习

